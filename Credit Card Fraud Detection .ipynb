{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bee6d016",
   "metadata": {},
   "source": [
    "# **Scenario:** Predict Credit Card Fraud using **SVM**, **KNN**, and **Naive Bayes**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78526fb8",
   "metadata": {},
   "source": [
    "Credit card fraud happens when someone — a fraudster or a thief — uses your stolen credit card or the information from that card to make unauthorized purchases in your name or take out cash advances using your account.\n",
    "\n",
    "### **Problem Statement:**\n",
    "\n",
    "Credit card companies such as **Citibank**, **HSBC**, and **American Express** need to recognize fraudulent credit card transactions so that customers are not charged for items that they did not purchase.\n",
    "\n",
    "### **Aim:**\n",
    "\n",
    "In this demo, you have to build a classification model to identify fraudulent credit card transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9840c809",
   "metadata": {},
   "source": [
    "### **Dataset Description**\n",
    "The datasets contains transactions made by credit cards in September 2013 by european cardholders. \n",
    "\n",
    "Presents transactions that occurred in two days, where we have **492** frauds out of **284,807** transactions. \n",
    "\n",
    "- **Time** - Number of seconds elapsed between this transaction and the first transaction in the dataset\n",
    "- **V1-V28** - Encrpted attributes (or columns) to protect user identities and sensitive features (v1-v28)\n",
    "- **Amount** - Transaction Amount\n",
    "- **Class** - **1** for fraudulent transactions, **0** otherwise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f292383c",
   "metadata": {},
   "source": [
    "### **Tasks to be performed:**\n",
    "\n",
    "- Install the required dependencies, import the required libraries and load the data set \n",
    "- Perform Exploratory Data Analysis (EDA) on the data set\n",
    "  -  Generate a Data Report using Pandas Profiling and record your observations\n",
    "  - Plot **Univariate Distributions**\n",
    "    - What is the distribution of the **amount** & **class** columns in the data set?\n",
    "    \n",
    "- Pre-process that data set for modeling\n",
    "  - Handle Missing values present in the data set\n",
    "  - Scale the data set using **RobustScaler()**\n",
    "  - Split the data into training and testing set using sklearn's **train_test_split** function\n",
    "- Modelling\n",
    "  - Build and evaluate a SVM Model\n",
    "  - Build and evaluate a KNN Model\n",
    "  - Build and evaluate a Naive Bayes Model\n",
    "\n",
    "- Model Optimization: Implement **GridSearchCV**\n",
    "- Model Boosting: Implement **Gradient Boosting** & **XGBoost**\n",
    "- Dealing with Imbalanced Classes: Re-sampling the data set\n",
    "- Model Interpertation: Interpret Fraud Detection Model With **Eli5**\n",
    "- Use **PyCaret** to find the best model and perform Automatic Hyperparameter tuning \n",
    "\n",
    "  - Import PyCaret and load the data set\n",
    "  - Initialize or setup the environment \n",
    "  - Compare Multiple Models and their Accuracy Metrics\n",
    "  - Create the model\n",
    "  - Tune the model\n",
    "  - Evaluate the model\n",
    "- Deploy the model using **Streamlit**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc33cd46",
   "metadata": {},
   "source": [
    "### Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d9dec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "sns.set()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eaef94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd = pd.read_csv(r\"C:\\Users\\Shivani Dussa\\Downloads\\creditcard.csv\")\n",
    "cd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b638a3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74ec0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfb74bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd.Class.value_counts()    # 0 means out of 284315 we could find only 492 frauds \n",
    "                               # // o means yes 1 means no // i.e., fruads is true (1) // no frauds false (0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def6822b",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe71390",
   "metadata": {},
   "source": [
    "### *Generate a Data Report using Pandas Profiling and record your observations*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c658232",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_profiling \n",
    "from pandas_profiling import ProfileReport\n",
    "prof = ProfileReport(cd)\n",
    "prof.to_file(output_file = 'output.html') # Creating the Data report "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292fd5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ProfileReport(cd).to_notebook_iframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4562dd3f",
   "metadata": {},
   "source": [
    "___\n",
    "**Observations:**\n",
    "\n",
    "- There are **31** variables or features in the dataframe and the total number of instances or rows are **2,84,807**\n",
    "- We have **30** Numeric and **1** Boolean variable\n",
    "- There are no missing cells in the dataset which is a big relief\n",
    "- There are **773** duplicate rows in the data set which accounts for **0.3%** of the entire data set\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58c4c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cd.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a40e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82803208",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cd.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54131ba9",
   "metadata": {},
   "source": [
    "**Note:** Answer the following questions:\n",
    "\n",
    "- What columns seems to have **outliers** based on **min**, **max** and **percentile values**, **IQR range** along with the **standard deviation** and **mean absolute deviation**?\n",
    "- What columns have missing values? (Check the **Missing Values** section in **Pandas Profiling**)\n",
    "- What columns have high amount of zeros/NaN\n",
    "\n",
    "- What columns have **high variance** and **standard deviation**?\n",
    "- Comment on the distribution of the continuous values **(Real Number: ℝ≥0)**\n",
    "- Do you see any alarming trends in the extreme values (minimum 5 and maximum 5)?\n",
    "- How many booleans columns are there in the data set and out of those how many are imbalanced?\n",
    "- Check for **duplicate records** across all columns (**Check Warning Section**)\n",
    "\n",
    "- How many columns are categorical?\n",
    "  - Are those categories in sync with the domain categories?\n",
    "  - Check if all the categories are unique and they represent distinct information\n",
    "  - Is there any imbalance in the categorical columns?\n",
    "\n",
    "Based on the above questions and your observations, chart out a plan for **Data Pre-processing** and feature engineering\n",
    "\n",
    "**Note:** Feature Engineering (Feature Selection and Feature Creation)\n",
    "\n",
    "- From the **Interaction Tab**, write at least 3 observations that may be very crucial for prediction. Make sure that they are in story format\n",
    "\n",
    "**For Example:** Av monthly hours vs Satisfaction Level..\n",
    "\n",
    "- Check **Pearson** and **Spearman** tab in the **correlation** section and note down the columns which are highly correlated (Postive and Negative Correlation). Create two bands of thresholds. (Consider 60 (0.6) to 80 (0.8) or 80 to 100 as high) \n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "da54493b",
   "metadata": {},
   "source": [
    "What is the distribution of the Time & Amount columns in the data set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b6d8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(cd,x = 'Time')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402b29b6",
   "metadata": {},
   "source": [
    "- **16k members are transactions are very low**\n",
    "- **8103k people transcations are also very low**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dcf3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(cd,x = 'scaled_amount')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3870bb",
   "metadata": {},
   "source": [
    "- **we hae more amount transactions at upto 487**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130140f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd.Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22c74e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting above to percentage\n",
    "round((cd.Class.value_counts()/cd.shape[0]),5)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fdc640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have 99.827 are no frauds \n",
    "# 0.173 have frauds i.e., the prediction it has did is very low so from 100% data we have only 0.173% frauds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28df9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "ax = sns.countplot(cd[\"Class\"], color='green')\n",
    "for p in ax.patches:\n",
    "    x = p.get_bbox().get_points()[:,0]\n",
    "    y = p.get_bbox().get_points()[1,1]\n",
    "    ax.annotate('{:.2g}%'.format(100.*y/len(cd)), (x.mean(), y), ha='center', va='bottom')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d0ee5b",
   "metadata": {},
   "source": [
    "___\n",
    "**Observations:**\n",
    "\n",
    "The data set is **Highly Unbalanced** with only **0.17%** of transactions being classified as **Fraudulent**. \n",
    "\n",
    "Several ways to approach this Imbalance Classification problem:\n",
    "\n",
    "- **Acquire More Data** (Not Possible in our case)\n",
    "- **Changing the performance metric:**\n",
    " - Use the **Confusion Matrix**\n",
    " - **F1-Score** (Weighted Average of **Precision** & **Recall**)\n",
    " - **ROC Curves**\n",
    "\n",
    "- **Re-sampling the dataset:** Essentially this is a method that will process the data to have an approximate 50-50 ratio.\n",
    "\n",
    " - **Over-sampling**, which is adding copies of the under-represented class (better when you have little data)\n",
    "\n",
    " - **Under-sampling**, which deletes instances from the over-represented class (better when we have lot's of data)\n",
    "\n",
    "**NOTE:** We will use the 2nd Method first and then, use **SMOTE** while using the 3rd approach\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a56957",
   "metadata": {},
   "source": [
    "## Data Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40514c4",
   "metadata": {},
   "source": [
    "**RobustScaler:** Unlike the previous scalers, the \n",
    "centering and scaling statistics of RobustScaler is based on percentiles and are therefore not influenced by a few number of very large marginal outliers. Consequently, the resulting range of the transformed feature values is larger than for the previous scalers and, more importantly, are approximately similar: for both features most of the transformed values lie in a [-2, 3] range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ff93be",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd['Amount'].values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30e1f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd['Time'].values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aaa645c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "rs = RobustScaler()\n",
    "\n",
    "# we are adding the scaled amount and scaled time by using fit transform and droping the columns amount and time from dataset\n",
    "cd['scaled_amount'] = rs.fit_transform(cd['Amount'].values.reshape(-1,1))\n",
    "cd['scaled_time'] = rs.fit_transform(cd['Time'].values.reshape(-1,1))\n",
    "cd.drop(['Amount','Time'],axis = 1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c27fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e260ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f39175",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd = cd[['scaled_amount', 'scaled_time','V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11',\n",
    "       'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21',\n",
    "       'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Class']]\n",
    "cd.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a5cb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = cd.iloc[:,cd.columns != 'Class']\n",
    "y = cd.iloc[:,cd.columns == 'Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76473b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "...     X, y,test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a832cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape , y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a777cc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape , y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a36c95",
   "metadata": {},
   "source": [
    "## Model Building "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cda1b8",
   "metadata": {},
   "source": [
    "### SVM\n",
    "- Baseline Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2aa0e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "shiv = svm.LinearSVC(random_state = 20)\n",
    "shiv.fit(X_train,y_train)\n",
    "#pred = shiv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6758ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = shiv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b38ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437302ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here from(truly ngtv) 85282 it predicted fraud data is 106(truly positv) from 106(truly pstv) + 41(false ngtv) = 147 \n",
    "# it predicted  14 (false positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e24770",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,precision_score,f1_score,recall_score,roc_auc_score\n",
    "svm_acc = accuracy_score(y_test,pred)\n",
    "svm_preci = precision_score(y_test,pred)\n",
    "svm_recal = recall_score(y_test,pred)\n",
    "svm_f1 = f1_score(y_test,pred)\n",
    "svm_roc_auc = roc_auc_score(y_test,pred)\n",
    "print('Accuracy:',svm_acc)\n",
    "print('Precision:',svm_preci)\n",
    "print('recall:',svm_recal)\n",
    "print('f1 score:',svm_f1)\n",
    "print('roc auc:',svm_roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe5a34b",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778491e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a20945",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "darsh = KNeighborsClassifier(n_neighbors = 3,metric = 'euclidean')  # here k = 3\n",
    "darsh.fit(X_train,y_train)\n",
    "predi = darsh.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d7a92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test,predi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d61092",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,precision_score,f1_score,recall_score,roc_auc_score,classification_report\n",
    "knn_acc = accuracy_score(y_test,predi)\n",
    "knn_preci = precision_score(y_test,predi)\n",
    "knn_recal = recall_score(y_test,predi)\n",
    "knn_f1 = f1_score(y_test,predi)\n",
    "knn_roc_auc = roc_auc_score(y_test,predi)\n",
    "print('Accuracy:',knn_acc)\n",
    "print('Precision:',knn_preci)\n",
    "print('recall:',knn_recal)\n",
    "print('f1 score:',knn_f1)\n",
    "print('roc auc:',knn_roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81e8b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,predi))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13b4e1d",
   "metadata": {},
   "source": [
    "- **macro avg**\n",
    " - This function computes f1 for each label, and returns the average without considering the proportion for each label in the dataset\n",
    " \n",
    "- **weighted avg**\n",
    "\n",
    " - This function computes f1 for each label, and returns the average considering the proportion for each label in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3764c4",
   "metadata": {},
   "source": [
    "## How to choose K in KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bd2820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell will take 30-40 mins to execute\n",
    "error_rate = []\n",
    "for i in range(1,40):\n",
    "    knn = KNeighborsClassifier(n_neighbors = i)\n",
    "    knn.fit(X_train,y_train)\n",
    "    pred_i = knn.predict(X_test)\n",
    "    error_rate.append(np.mean(pred_i != y_test))\n",
    "    \n",
    "plt.figure(figsize = (10,6))\n",
    "plt.plot(range(1,40),error_rate)\n",
    "\n",
    "plt.title('Error Rate vs K value')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Error rate')\n",
    "\n",
    "print(\"Minimum error:-\",min(error_rate),\"at k = \",error_rate.index(min(error_rate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa887b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a42ead0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d12acea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e94b294",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f00a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_rate = []\n",
    "for i in range(1,40):\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X_train,y_train)\n",
    "    pred_i = knn.predict(X_test)\n",
    "    error_rate.append(np.mean(pred_i != y_test))\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(range(1,40),error_rate)\n",
    "\n",
    "plt.title('Error Rate vs. K Value')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Error Rate')\n",
    "\n",
    "print(\"Minimum error:-\",min(error_rate),\"at K =\",error_rate.index(min(error_rate)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce33aa52",
   "metadata": {},
   "source": [
    "## Re-train the KNN Model with Optimal value k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24689165",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier(n_neighbors = 7 ,metric = 'euclidean')\n",
    "model.fit(X_train,y_train)\n",
    "pred1 = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e82c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,pred1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751d30c0",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b321783f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "# create and Train a Guassian Classifier\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train,y_train)\n",
    "pred2 = gnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf2afac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test,pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1697cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,precision_score,f1_score,recall_score,roc_auc_score,classification_report\n",
    "acc = accuracy_score(y_test,pred1)\n",
    "preci = precision_score(y_test,pred1)\n",
    "recal = recall_score(y_test,pred1)\n",
    "f1 = f1_score(y_test,pred1)\n",
    "roc_auc = roc_auc_score(y_test,pred1)\n",
    "print('Accuracy:',acc)\n",
    "print('Precision:',preci)\n",
    "print('recall:',recal)\n",
    "print('f1 score:',f1)\n",
    "print('roc auc:',roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7334d79f",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4ce701",
   "metadata": {},
   "source": [
    "- **Precision:**\n",
    "  - What percentage of positive predictions made were correct? This is **Precision**\n",
    "  - No. of True Positives divided by the no. of True Positives plus the No. of False Positives\n",
    " \n",
    "- **Recall:** Ratio of True Positives to all the positives in your Dataset\n",
    "\n",
    "- **When to use Precision & Recall:** \n",
    " - In the credit card fraud detection task, lets say we modify the model slightly, and identify a single transaction correctly as fraud. \n",
    "\n",
    " - Now, our precision will be 1.0 (no false positives) but our recall will be very low because we will still have many false negatives. \n",
    "\n",
    " - If we go to the other extreme and classify all transactions as fraud, we will have a recall of 1.0 — we’ll catch every fraud transaction — but our precision will be very low and we’ll misclassify many legit transactions. In other words, as we increase precision we decrease recall and vice-versa.\n",
    "\n",
    "- **F1-Score:**\n",
    " F1 Score is the weighted average of Precision and Recall. F1 is usually more useful than accuracy, especially when we have an uneven class distribution\n",
    "\n",
    " - **When to use F1-Score:** \n",
    "   - Useful when you have data with imbalance classes\n",
    "   - Let us say, we have a model with a precision of 1, and recall of 0 which gives a simple average as 0.5 and an F1 score of 0\n",
    "   - If one of the parameters is low, the second one no longer matters in the F1 score \n",
    "   - The F1 score favors classifiers that have similar precision and recall\n",
    "   - F1 score is a better measure to use if you are seeking a balance between Precision and Recall\n",
    "\n",
    "- **roc_auc_score**\n",
    " - roc_auc_score always runs from 0 to 1, and is sorting predictive possibilities. 0.5 is the baseline for random guessing\n",
    " - This metric shows how good at ranking predictions our model is\n",
    "  \n",
    "   When to/ not to use it?\n",
    "    - Should not use it when your data is heavily imbalanced\n",
    "    - Should use it when you care equally about positive and negative classes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478bcf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd.Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14ee16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame([['Naive Bayes Classifier',acc,preci,recal,f1,roc_auc],\n",
    "                       ['Support Vector Machine',svm_acc,svm_preci,svm_f1,svm_roc_auc],\n",
    "                       ['K Nearest Neighbor',knn_acc,knn_preci,knn_f1,knn_roc_auc]\n",
    "                       ],\n",
    "            columns = ['Model','Accuracy','Precision','Recall','f1 score','ROC'])\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5035c2cc",
   "metadata": {},
   "source": [
    "## Model Optimization: GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4569aed3",
   "metadata": {},
   "source": [
    "**SVM Hyperparameters:**\n",
    "\n",
    "- **Gamma**\n",
    " - Used with non-linear SVM. Commonly used non-linear kernel is the Radial Basis Function (RBF)\n",
    " - Gamma parameter of RBF controls the distance of the influence of a single training point\n",
    " - Low values of gamma indicate a large similarity radius which results in more points being grouped together\n",
    " - For high values of gamma, the points need to be very close to each other in order to be considered in the same group (or class)\n",
    " - Models with very large gamma values tend to overfit.\n",
    " \n",
    "- **C**\n",
    " - Adds a penalty for each misclassified data point\n",
    " - If c is small, the penalty for misclassified points is low so a decision boundary with a large margin is chosen at the expense of a greater number of misclassifications\n",
    " - If c is large, SVM tries to minimize the number of misclassified examples due to high penalty which results in a decision boundary with a smaller margin\n",
    " - Penalty is not same for all misclassified examples\n",
    " - It is directly proportional to the distance to decision boundary\n",
    "\n",
    "**NOTE:** If you want to learn more about SVM Hyper-parameters, [**Click Here!**](http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f826d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "param_grid = {'C':[0.1,1,10],\n",
    "             'gamma':['scale','auto'],\n",
    "             'kernel':['rbf']}\n",
    "svc_grid = GridSearchCV(SVC(),param_grid,refit = True,verbose = 3,cv = 2)\n",
    "\n",
    "svc_grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cea653d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best Parameters:',svc_grid.best_params_,'Best estimator:',svc_grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4e57da",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_p = svc_grid.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test,g_p))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59066eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,precision_score,f1_score,recall_score,roc_auc_score,classification_report\n",
    "grid_acc = accuracy_score(y_test,g_p)\n",
    "grid_preci = precision_score(y_test,g_p)\n",
    "grid_recal = recall_score(y_test,g_p)\n",
    "grid_f1 = f1_score(y_test,g_p)\n",
    "grid_roc_auc = roc_auc_score(y_test,g_p)\n",
    "print('Accuracy:',grid_acc)\n",
    "print('Precision:',grid_preci)\n",
    "print('recall:',grid_recal)\n",
    "print('f1 score:',grid_f1)\n",
    "print('roc auc:',grid_roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b56f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd2 = {'Model': 'SVC With GridSearchCV', 'Accuracy': grid_acc, 'Precision': grid_preci, 'Recall': grid_recal, \n",
    "            'f1 score': grid_f1, 'ROC': grid_roc_auc} \n",
    "results2 = results.append(cd2,ignore_index = True)\n",
    "results2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3230f2",
   "metadata": {},
   "source": [
    "## Model Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faedb512",
   "metadata": {},
   "source": [
    "**Gradient Boosting Classifier**\n",
    "\n",
    "Parameters\n",
    "\n",
    "- **n_estimators:** Represents the number of trees in the forest\n",
    "- **learning_rate:** Shrinks the contribution of each tree by learning_rate.\n",
    "- **max_features:** Represents the number of features to consider when looking for the best split \n",
    "- **max_depth:** Indicates how deep the built tree can be\n",
    "- **random_state:** Random state ensures that the splits that you generate are reproducible. Used as a seed to the random number generator. This ensures that the random numbers are generated in the same order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9264a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "\n",
    "gbc = GradientBoostingClassifier(n_estimators = 200,learning_rate = 0.1,max_features = 2,max_depth = 2,random_state = 0)\n",
    "gbc.fit(X_train,y_train)\n",
    "\n",
    "print('Accuracy score(training set):{0:3f}'.format(gbc.score(X_train,y_train)))\n",
    "print('Accuracy score(testing set):{0:3f}'.format(gbc.score(X_train,y_train)))\n",
    "\n",
    "pred3 = gbc.predict(X_test)\n",
    "\n",
    "print('Confusion matrix:')\n",
    "print(confusion_matrix(y_test,pred3))\n",
    "\n",
    "print('Classification report:')\n",
    "print(classification_report(y_test,pred3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b9d894",
   "metadata": {},
   "source": [
    "**Let us try different learning rates to compare the performance of the classifier's performance at different learning rates**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc84b2bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
